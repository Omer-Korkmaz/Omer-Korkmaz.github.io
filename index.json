[{"categories":["python"],"contents":"Decision trees are supervised machine learning algorithms that are used for classification and regression. You can train a model that learns from existing data and predicts the value of desired variable.\nDecision trees are popular, since they are easy to understand and can be visualized. You can use them with both numerical and categorical data. On the other hand, it is quite possible to create useless trees. You can easily over-train them by creating too complicated trees. Moreover, it is possible to create trees that are biased if your dataset is unbalanced.\nPython’s Scikit-learn library 1. enables us to use state-of-the-art machine learning algorithms, including decision trees, with ease of use.\nFollowing is a sample implementation of a decision tree, using a toy dataset 2 (i.e. fictional and constructed conveniently for analysis). Dataset is about patients, all of them suffered from the same illness. There are multiple drug choices. Model is trying to predict which drug should be used with a future patient.\nLoading Libraries and Checking Data\rLoading necessary libraries:\nimport numpy as np import pandas as pd\rimport matplotlib.pyplot as plt\rfrom sklearn.tree import DecisionTreeClassifier\rfrom sklearn import preprocessing\rfrom sklearn.model_selection import train_test_split\rfrom sklearn import metrics\rfrom sklearn.externals.six import StringIO\r## C:\\Users\\korkm\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we\u0026#39;ve dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\r## \u0026quot;(https://pypi.org/project/six/).\u0026quot;, FutureWarning)\rimport pydotplus\rfrom sklearn import tree\rfrom sklearn.tree import export_graphviz\rimport graphviz\rimport itertools\rdrug_data = pd.read_csv(\u0026quot;https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/drug200.csv\u0026quot;, delimiter=\u0026quot;,\u0026quot;)\rData is imported, so let’s check out the data:\ndrug_data.head\r## \u0026lt;bound method NDFrame.head of Age Sex BP Cholesterol Na_to_K Drug\r## 0 23 F HIGH HIGH 25.355 drugY\r## 1 47 M LOW HIGH 13.093 drugC\r## 2 47 M LOW HIGH 10.114 drugC\r## 3 28 F NORMAL HIGH 7.798 drugX\r## 4 61 F LOW HIGH 18.043 drugY\r## .. ... .. ... ... ... ...\r## 195 56 F LOW HIGH 11.567 drugC\r## 196 16 M LOW HIGH 12.006 drugC\r## 197 52 M NORMAL HIGH 9.894 drugX\r## 198 23 M NORMAL NORMAL 14.020 drugX\r## 199 40 F LOW NORMAL 11.349 drugX\r## ## [200 rows x 6 columns]\u0026gt;\r\rData preparation\rDefining X as the feature matrix (data of drug_data) and checking out the array:\nX = drug_data[[\u0026#39;Age\u0026#39;, \u0026#39;Sex\u0026#39;, \u0026#39;BP\u0026#39;, \u0026#39;Cholesterol\u0026#39;, \u0026#39;Na_to_K\u0026#39;]].values\rX[0:10]\r## array([[23, \u0026#39;F\u0026#39;, \u0026#39;HIGH\u0026#39;, \u0026#39;HIGH\u0026#39;, 25.355],\r## [47, \u0026#39;M\u0026#39;, \u0026#39;LOW\u0026#39;, \u0026#39;HIGH\u0026#39;, 13.093],\r## [47, \u0026#39;M\u0026#39;, \u0026#39;LOW\u0026#39;, \u0026#39;HIGH\u0026#39;, 10.113999999999999],\r## [28, \u0026#39;F\u0026#39;, \u0026#39;NORMAL\u0026#39;, \u0026#39;HIGH\u0026#39;, 7.797999999999999],\r## [61, \u0026#39;F\u0026#39;, \u0026#39;LOW\u0026#39;, \u0026#39;HIGH\u0026#39;, 18.043],\r## [22, \u0026#39;F\u0026#39;, \u0026#39;NORMAL\u0026#39;, \u0026#39;HIGH\u0026#39;, 8.607000000000001],\r## [49, \u0026#39;F\u0026#39;, \u0026#39;NORMAL\u0026#39;, \u0026#39;HIGH\u0026#39;, 16.275],\r## [41, \u0026#39;M\u0026#39;, \u0026#39;LOW\u0026#39;, \u0026#39;HIGH\u0026#39;, 11.037],\r## [60, \u0026#39;M\u0026#39;, \u0026#39;NORMAL\u0026#39;, \u0026#39;HIGH\u0026#39;, 15.171],\r## [43, \u0026#39;M\u0026#39;, \u0026#39;LOW\u0026#39;, \u0026#39;NORMAL\u0026#39;, 19.368]], dtype=object)\rConverting categorical variables into indicator variables:\nle_sex = preprocessing.LabelEncoder()\rle_sex.fit([\u0026#39;F\u0026#39;,\u0026#39;M\u0026#39;])\r## LabelEncoder()\rX[:,1] = le_sex.transform(X[:,1]) le_BP = preprocessing.LabelEncoder()\rle_BP.fit([ \u0026#39;LOW\u0026#39;, \u0026#39;NORMAL\u0026#39;, \u0026#39;HIGH\u0026#39;])\r## LabelEncoder()\rX[:,2] = le_BP.transform(X[:,2])\rle_Chol = preprocessing.LabelEncoder()\rle_Chol.fit([ \u0026#39;NORMAL\u0026#39;, \u0026#39;HIGH\u0026#39;])\r## LabelEncoder()\rX[:,3] = le_Chol.transform(X[:,3]) X[0:5]\r## array([[23, 0, 0, 0, 25.355],\r## [47, 1, 1, 0, 13.093],\r## [47, 1, 1, 0, 10.113999999999999],\r## [28, 0, 2, 0, 7.797999999999999],\r## [61, 0, 1, 0, 18.043]], dtype=object)\rFilling the target variable:\ny = drug_data[\u0026quot;Drug\u0026quot;]\ry[0:5]\r## 0 drugY\r## 1 drugC\r## 2 drugC\r## 3 drugX\r## 4 drugY\r## Name: Drug, dtype: object\r\rSetting Up the Model\rSetting up the decision tree, splitting data into training (%70) and test sets (%30):\nX_trainset, X_testset, y_trainset, y_testset = train_test_split(X, y, test_size=0.3, random_state=3)\rChecking the dimensions of the sets:\nprint (\u0026#39;Train set:\u0026#39;, X_trainset.shape, y_trainset.shape)\r## Train set: (140, 5) (140,)\rprint (\u0026#39;Test set:\u0026#39;, X_testset.shape, y_testset.shape)\r## Test set: (60, 5) (60,)\rTraining the model\ndrugTree = DecisionTreeClassifier(criterion=\u0026quot;entropy\u0026quot;, max_depth = 4)\rdrugTree.fit(X_trainset,y_trainset)\r## DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion=\u0026#39;entropy\u0026#39;,\r## max_depth=4, max_features=None, max_leaf_nodes=None,\r## min_impurity_decrease=0.0, min_impurity_split=None,\r## min_samples_leaf=1, min_samples_split=2,\r## min_weight_fraction_leaf=0.0, presort=\u0026#39;deprecated\u0026#39;,\r## random_state=None, splitter=\u0026#39;best\u0026#39;)\r#Prediction\npredTree = drugTree.predict(X_testset)\rpredTree\r## array([\u0026#39;drugY\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugC\u0026#39;, \u0026#39;drugY\u0026#39;,\r## \u0026#39;drugA\u0026#39;, \u0026#39;drugB\u0026#39;, \u0026#39;drugA\u0026#39;, \u0026#39;drugY\u0026#39;, \u0026#39;drugA\u0026#39;, \u0026#39;drugY\u0026#39;, \u0026#39;drugY\u0026#39;,\r## \u0026#39;drugX\u0026#39;, \u0026#39;drugY\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugB\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugX\u0026#39;,\r## \u0026#39;drugY\u0026#39;, \u0026#39;drugY\u0026#39;, \u0026#39;drugY\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugB\u0026#39;, \u0026#39;drugY\u0026#39;, \u0026#39;drugY\u0026#39;,\r## \u0026#39;drugA\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugB\u0026#39;, \u0026#39;drugC\u0026#39;, \u0026#39;drugC\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugX\u0026#39;,\r## \u0026#39;drugC\u0026#39;, \u0026#39;drugY\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugA\u0026#39;, \u0026#39;drugY\u0026#39;,\r## \u0026#39;drugC\u0026#39;, \u0026#39;drugY\u0026#39;, \u0026#39;drugA\u0026#39;, \u0026#39;drugY\u0026#39;, \u0026#39;drugY\u0026#39;, \u0026#39;drugY\u0026#39;, \u0026#39;drugY\u0026#39;,\r## \u0026#39;drugY\u0026#39;, \u0026#39;drugB\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugY\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugY\u0026#39;, \u0026#39;drugY\u0026#39;,\r## \u0026#39;drugA\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugY\u0026#39;, \u0026#39;drugX\u0026#39;], dtype=object)\rChecking Testset to Visually Compare Predictions\nnp.asarray(y_testset)\r## array([\u0026#39;drugY\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugC\u0026#39;, \u0026#39;drugY\u0026#39;,\r## \u0026#39;drugA\u0026#39;, \u0026#39;drugB\u0026#39;, \u0026#39;drugA\u0026#39;, \u0026#39;drugY\u0026#39;, \u0026#39;drugA\u0026#39;, \u0026#39;drugY\u0026#39;, \u0026#39;drugY\u0026#39;,\r## \u0026#39;drugX\u0026#39;, \u0026#39;drugY\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugB\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugX\u0026#39;,\r## \u0026#39;drugY\u0026#39;, \u0026#39;drugY\u0026#39;, \u0026#39;drugY\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugB\u0026#39;, \u0026#39;drugY\u0026#39;, \u0026#39;drugY\u0026#39;,\r## \u0026#39;drugA\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugB\u0026#39;, \u0026#39;drugC\u0026#39;, \u0026#39;drugC\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugX\u0026#39;,\r## \u0026#39;drugC\u0026#39;, \u0026#39;drugY\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugA\u0026#39;, \u0026#39;drugY\u0026#39;,\r## \u0026#39;drugC\u0026#39;, \u0026#39;drugY\u0026#39;, \u0026#39;drugA\u0026#39;, \u0026#39;drugY\u0026#39;, \u0026#39;drugY\u0026#39;, \u0026#39;drugY\u0026#39;, \u0026#39;drugY\u0026#39;,\r## \u0026#39;drugX\u0026#39;, \u0026#39;drugB\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugY\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugY\u0026#39;, \u0026#39;drugY\u0026#39;,\r## \u0026#39;drugA\u0026#39;, \u0026#39;drugX\u0026#39;, \u0026#39;drugY\u0026#39;, \u0026#39;drugX\u0026#39;], dtype=object)\r#Evaluation\nprint(\u0026quot;DecisionTrees\u0026#39;s Accuracy: \u0026quot;, metrics.accuracy_score(y_testset, predTree))\r## DecisionTrees\u0026#39;s Accuracy: 0.9833333333333333\r\rVisualization\rdot_data = tree.export_graphviz(drugTree, out_file=None, feature_names=drug_data.columns[0:5], class_names=np.unique(y_trainset), filled=True, rounded=True, special_characters=True) graph = graphviz.Source(dot_data) graph\r## \u0026lt;graphviz.files.Source object at 0x0000000032CCBC88\u0026gt;\r\r\r Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011. URL: http://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html↩\n\rThis implementation is from a notebook used in one of IBM’s courses about machine learning (https://www.coursera.org/learn/machine-learning-with-python/) and is released under the terms of the MIT License.↩\n\r\r\r","permalink":"/2020/05/machine-learning-with-python-part-1-decision-trees/","tags":["datascience","python","scikit-learn","machine learning","decision trees"],"title":"Machine Learning with Python Part 1: Decision Trees"},{"categories":["r"],"contents":"\nEdit: Data and plots are updaten on May 21, 2020.\nR has various ways to visualize data. In my opinion, ggplot2 is the most elegant, practical and somewhat easy to learn way to do so. It has a very common-sensical logic for creating graphs. It implements the grammar of graphics1.\nFollowing graphs about Covid19 are built with #ggplot2, using data provided by John Hopkins University2.\nData wrangling is done mostly using tidyverse3 package.\n1. Loading Data and Checking Contents\rLoading tidyverse, magrittr (For pipes) and lubridate (For date ops.):\nlibrary(\u0026quot;tidyverse\u0026quot;)\rlibrary(\u0026quot;magrittr\u0026quot;)\rlibrary(\u0026quot;lubridate\u0026quot;)\rDownloading confirmed cases data from JHU repo and loading into R:\ntime_series_raw_confirmed \u0026lt;- read.csv(\u0026quot;https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\u0026quot;)\rChecking out the dimensions:\ndim(time_series_raw_confirmed)\r## [1] 266 124\rChecking out the first few rows and columns:\nas_tibble(time_series_raw_confirmed)\r## # A tibble: 266 x 124\r## Province.State Country.Region Lat Long X1.22.20 X1.23.20 X1.24.20\r## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt;\r## 1 \u0026quot;\u0026quot; Afghanistan 33 65 0 0 0\r## 2 \u0026quot;\u0026quot; Albania 41.2 20.2 0 0 0\r## 3 \u0026quot;\u0026quot; Algeria 28.0 1.66 0 0 0\r## 4 \u0026quot;\u0026quot; Andorra 42.5 1.52 0 0 0\r## 5 \u0026quot;\u0026quot; Angola -11.2 17.9 0 0 0\r## 6 \u0026quot;\u0026quot; Antigua and B~ 17.1 -61.8 0 0 0\r## 7 \u0026quot;\u0026quot; Argentina -38.4 -63.6 0 0 0\r## 8 \u0026quot;\u0026quot; Armenia 40.1 45.0 0 0 0\r## 9 \u0026quot;Australian C~ Australia -35.5 149. 0 0 0\r## 10 \u0026quot;New South Wa~ Australia -33.9 151. 0 0 0\r## # ... with 256 more rows, and 117 more variables: X1.25.20 \u0026lt;int\u0026gt;,\r## # X1.26.20 \u0026lt;int\u0026gt;, X1.27.20 \u0026lt;int\u0026gt;, X1.28.20 \u0026lt;int\u0026gt;, X1.29.20 \u0026lt;int\u0026gt;,\r## # X1.30.20 \u0026lt;int\u0026gt;, X1.31.20 \u0026lt;int\u0026gt;, X2.1.20 \u0026lt;int\u0026gt;, X2.2.20 \u0026lt;int\u0026gt;,\r## # X2.3.20 \u0026lt;int\u0026gt;, X2.4.20 \u0026lt;int\u0026gt;, X2.5.20 \u0026lt;int\u0026gt;, X2.6.20 \u0026lt;int\u0026gt;, X2.7.20 \u0026lt;int\u0026gt;,\r## # X2.8.20 \u0026lt;int\u0026gt;, X2.9.20 \u0026lt;int\u0026gt;, X2.10.20 \u0026lt;int\u0026gt;, X2.11.20 \u0026lt;int\u0026gt;,\r## # X2.12.20 \u0026lt;int\u0026gt;, X2.13.20 \u0026lt;int\u0026gt;, X2.14.20 \u0026lt;int\u0026gt;, X2.15.20 \u0026lt;int\u0026gt;,\r## # X2.16.20 \u0026lt;int\u0026gt;, X2.17.20 \u0026lt;int\u0026gt;, X2.18.20 \u0026lt;int\u0026gt;, X2.19.20 \u0026lt;int\u0026gt;,\r## # X2.20.20 \u0026lt;int\u0026gt;, X2.21.20 \u0026lt;int\u0026gt;, X2.22.20 \u0026lt;int\u0026gt;, X2.23.20 \u0026lt;int\u0026gt;,\r## # X2.24.20 \u0026lt;int\u0026gt;, X2.25.20 \u0026lt;int\u0026gt;, X2.26.20 \u0026lt;int\u0026gt;, X2.27.20 \u0026lt;int\u0026gt;,\r## # X2.28.20 \u0026lt;int\u0026gt;, X2.29.20 \u0026lt;int\u0026gt;, X3.1.20 \u0026lt;int\u0026gt;, X3.2.20 \u0026lt;int\u0026gt;,\r## # X3.3.20 \u0026lt;int\u0026gt;, X3.4.20 \u0026lt;int\u0026gt;, X3.5.20 \u0026lt;int\u0026gt;, X3.6.20 \u0026lt;int\u0026gt;, X3.7.20 \u0026lt;int\u0026gt;,\r## # X3.8.20 \u0026lt;int\u0026gt;, X3.9.20 \u0026lt;int\u0026gt;, X3.10.20 \u0026lt;int\u0026gt;, X3.11.20 \u0026lt;int\u0026gt;,\r## # X3.12.20 \u0026lt;int\u0026gt;, X3.13.20 \u0026lt;int\u0026gt;, X3.14.20 \u0026lt;int\u0026gt;, X3.15.20 \u0026lt;int\u0026gt;,\r## # X3.16.20 \u0026lt;int\u0026gt;, X3.17.20 \u0026lt;int\u0026gt;, X3.18.20 \u0026lt;int\u0026gt;, X3.19.20 \u0026lt;int\u0026gt;,\r## # X3.20.20 \u0026lt;int\u0026gt;, X3.21.20 \u0026lt;int\u0026gt;, X3.22.20 \u0026lt;int\u0026gt;, X3.23.20 \u0026lt;int\u0026gt;,\r## # X3.24.20 \u0026lt;int\u0026gt;, X3.25.20 \u0026lt;int\u0026gt;, X3.26.20 \u0026lt;int\u0026gt;, X3.27.20 \u0026lt;int\u0026gt;,\r## # X3.28.20 \u0026lt;int\u0026gt;, X3.29.20 \u0026lt;int\u0026gt;, X3.30.20 \u0026lt;int\u0026gt;, X3.31.20 \u0026lt;int\u0026gt;,\r## # X4.1.20 \u0026lt;int\u0026gt;, X4.2.20 \u0026lt;int\u0026gt;, X4.3.20 \u0026lt;int\u0026gt;, X4.4.20 \u0026lt;int\u0026gt;, X4.5.20 \u0026lt;int\u0026gt;,\r## # X4.6.20 \u0026lt;int\u0026gt;, X4.7.20 \u0026lt;int\u0026gt;, X4.8.20 \u0026lt;int\u0026gt;, X4.9.20 \u0026lt;int\u0026gt;, X4.10.20 \u0026lt;int\u0026gt;,\r## # X4.11.20 \u0026lt;int\u0026gt;, X4.12.20 \u0026lt;int\u0026gt;, X4.13.20 \u0026lt;int\u0026gt;, X4.14.20 \u0026lt;int\u0026gt;,\r## # X4.15.20 \u0026lt;int\u0026gt;, X4.16.20 \u0026lt;int\u0026gt;, X4.17.20 \u0026lt;int\u0026gt;, X4.18.20 \u0026lt;int\u0026gt;,\r## # X4.19.20 \u0026lt;int\u0026gt;, X4.20.20 \u0026lt;int\u0026gt;, X4.21.20 \u0026lt;int\u0026gt;, X4.22.20 \u0026lt;int\u0026gt;,\r## # X4.23.20 \u0026lt;int\u0026gt;, X4.24.20 \u0026lt;int\u0026gt;, X4.25.20 \u0026lt;int\u0026gt;, X4.26.20 \u0026lt;int\u0026gt;,\r## # X4.27.20 \u0026lt;int\u0026gt;, X4.28.20 \u0026lt;int\u0026gt;, X4.29.20 \u0026lt;int\u0026gt;, X4.30.20 \u0026lt;int\u0026gt;,\r## # X5.1.20 \u0026lt;int\u0026gt;, X5.2.20 \u0026lt;int\u0026gt;, X5.3.20 \u0026lt;int\u0026gt;, ...\rDataframe has 266 rows (One row for each country/state) and 106 columns (One column for each day, starting on January 22).\n\r2. Cleaning Data\rWriting a function4 to pivot the data into longer format and summarize by country (I might work on same data in the future or on deaths and recoveries, so, better to write a function):\ntidydatafunction \u0026lt;- function(data) {\rdata %\u0026lt;\u0026gt;% select(everything(), -\u0026#39;Province.State\u0026#39;, -\u0026#39;Lat\u0026#39;, -\u0026#39;Long\u0026#39;) %\u0026gt;% rename(country = Country.Region) # Removing unnecessary columns and renaming one\rdata %\u0026lt;\u0026gt;% pivot_longer(-country, names_to = \u0026quot;date\u0026quot;, values_to = \u0026quot;count\u0026quot;) # Pivoting data into longer format\rdata %\u0026lt;\u0026gt;% mutate(date = date %\u0026gt;% substr(2,8)%\u0026gt;% mdy()) # Removing the \u0026quot;x\u0026quot;s and converting to dates\rdata %\u0026lt;\u0026gt;% group_by(country, date) %\u0026gt;% summarise(accumulated_cases = sum(count, na.rm = TRUE)) %\u0026gt;% as.data.frame() # Group by country and summarise on case data\rreturn(data)\r}\rCleaning previously loaded data into new tidy dataset:\ntime_series_tidy_confirmed \u0026lt;- time_series_raw_confirmed %\u0026gt;% tidydatafunction()\rChecking out new, tidy dataset:\nas_tibble(time_series_tidy_confirmed) %\u0026gt;%\rarrange(desc(accumulated_cases)) # Sorting desc. to see top numbers\r## # A tibble: 22,560 x 3\r## country date accumulated_cases\r## \u0026lt;chr\u0026gt; \u0026lt;date\u0026gt; \u0026lt;int\u0026gt;\r## 1 US 2020-05-20 1551853\r## 2 US 2020-05-19 1528568\r## 3 US 2020-05-18 1508308\r## 4 US 2020-05-17 1486757\r## 5 US 2020-05-16 1467820\r## 6 US 2020-05-15 1442824\r## 7 US 2020-05-14 1417774\r## 8 US 2020-05-13 1390406\r## 9 US 2020-05-12 1369376\r## 10 US 2020-05-11 1347881\r## # ... with 22,550 more rows\rAdding daily cases as calculated field from accumulated cases and saving as a new data frame:\ntime_series_tidy_confirmed_with_daily \u0026lt;- time_series_tidy_confirmed %\u0026gt;%\rgroup_by(country) %\u0026gt;% # Group by country\rarrange(country, date) %\u0026gt;% # Sort asc. by country and then date\rmutate(daily_cases = c(0,diff(accumulated_cases))) # Calculate daily cases\rtime_series_tidy_confirmed_with_daily %\u0026gt;%\rarrange(desc(accumulated_cases)) # Sorting desc. to see top numbers\r## # A tibble: 22,560 x 4\r## # Groups: country [188]\r## country date accumulated_cases daily_cases\r## \u0026lt;chr\u0026gt; \u0026lt;date\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 US 2020-05-20 1551853 23285\r## 2 US 2020-05-19 1528568 20260\r## 3 US 2020-05-18 1508308 21551\r## 4 US 2020-05-17 1486757 18937\r## 5 US 2020-05-16 1467820 24996\r## 6 US 2020-05-15 1442824 25050\r## 7 US 2020-05-14 1417774 27368\r## 8 US 2020-05-13 1390406 21030\r## 9 US 2020-05-12 1369376 21495\r## 10 US 2020-05-11 1347881 18621\r## # ... with 22,550 more rows\rFiltering Turkey, calculating daily cases from accumulated cases and saving as a new data frame:\nturkey_time_series_tidy_confirmed_with_daily \u0026lt;- time_series_tidy_confirmed %\u0026gt;%\rfilter(country == \u0026quot;Turkey\u0026quot;) %\u0026gt;% # Filtering Turkey\rarrange(date) %\u0026gt;% # Sort asc. by date\rmutate(daily_cases = c(0,diff(accumulated_cases))) # Calculate daily cases\rhead(turkey_time_series_tidy_confirmed_with_daily %\u0026gt;%\rarrange(desc(accumulated_cases))) # Sorting desc. to see top numbers\r## country date accumulated_cases daily_cases\r## 1 Turkey 2020-05-20 152587 972\r## 2 Turkey 2020-05-19 151615 1022\r## 3 Turkey 2020-05-18 150593 1158\r## 4 Turkey 2020-05-17 149435 1368\r## 5 Turkey 2020-05-16 148067 1610\r## 6 Turkey 2020-05-15 146457 1708\rListing top 9 countries in terms of total cases (Will come in handy later)\ntop_nine_countries \u0026lt;- time_series_tidy_confirmed_with_daily %\u0026gt;%\rfilter(date == max(date)) %\u0026gt;% # For the most recent day in data\rgroup_by(country) %\u0026gt;% # Group by country\rsummarise(total_case = sum(accumulated_cases, na.rm = TRUE)) %\u0026gt;% # Summarise on accumulated cases\rtop_n(9, total_case) %\u0026gt;% # Select top 9 countries by total cases\rarrange(desc(total_case)) %\u0026gt;% # Sort desc. to see in proper order\rselect(country) # Select only country names\rtop_nine_countries\r## # A tibble: 9 x 1\r## country ## \u0026lt;chr\u0026gt; ## 1 US ## 2 Russia ## 3 Brazil ## 4 United Kingdom\r## 5 Spain ## 6 Italy ## 7 France ## 8 Germany ## 9 Turkey\r#3. Plotting Some Graphs\nLet’s see how Turkey is doing, in terms of new cases.\nPlotting daily case trend for Turkey, black line and dots respresent actual case numbers and blue line is regression line:\nggplot(data = turkey_time_series_tidy_confirmed_with_daily, mapping = aes(x = date, y = daily_cases)) + # Passed on data, mapping and variables to plot, wrote explicitly on purpose\rgeom_line() + # Added line\rgeom_point() + # Added points\rgeom_smooth(se = FALSE) + # Added regression line, locally fitted with loess method labs(y = \u0026quot;Daily Cases\u0026quot;, x = \u0026quot;Date\u0026quot;, title = \u0026quot;Daily Covid19 Cases in Turkey\u0026quot;) # Axis labels and main title added\rIt seems that Turkey has reached the peak and now is on a downwards trend.\nLet’s see how top 9 countries (In terms of accumulated cases) are doing.\nPlotting daily case trend for top 9 countries, black line and dots respresent actual case numbers and blue line is regression line:\nggplot(data = filter(time_series_tidy_confirmed_with_daily, country == as_vector(top_nine_countries)), mapping = aes(x = date, y = daily_cases)) + # Passed on data, mapping and variables to plot, wrote explicitly on purpose\rgeom_line() + # Added line\rgeom_point() + # Added points\rgeom_smooth(se = FALSE) + # Added regression line, locally fitted with loess method labs(y = \u0026quot;Daily Cases\u0026quot;, x = \u0026quot;Date\u0026quot;, title = \u0026quot;Daily Covid19 Cases in Top 9 Countries\u0026quot;) + # Axis labels and main title added\rfacet_wrap(country~., nrow = 3, scales = \u0026quot;free\u0026quot;) \rAnd situation about accumulated cases is as following:\nPlotting accumulated case trend top 9 countries, black line and dots respresent actual case numbers and blue line is regression line:\noptions(scipen = 999999) # To see numbers as is, not in scientific format ggplot(data = filter(time_series_tidy_confirmed_with_daily, country == as_vector(top_nine_countries)), mapping = aes(x = date, y = accumulated_cases)) + # Passed on data, mapping and variables to plot, wrote explicitly on purpose\rgeom_line() + # Added line\rgeom_point() + # Added points\rgeom_smooth(se = FALSE) + # Added regression line, locally fitted with loess method labs(y = \u0026quot;Accumulated Cases\u0026quot;, x = \u0026quot;Date\u0026quot;, title = \u0026quot;Accumulated Covid19 Cases in Top 9 Countries\u0026quot;) + # Axis labels and main title added\rfacet_grid(country~., scales = \u0026quot;free_y\u0026quot;)\r\r\rIf you want to learn more about the theory behind the ggplot2 and layered grammar of graphics, I’d recommend reading “The Layered Grammar of Graphics”, http://vita.had.co.nz/papers/layered-grammar.pdf↩\n\rhttps://github.com/CSSEGISandData/COVID-19↩\n\rTidyverse is a set of R packages for data science. It includes ggplot2 as well as other packages to use in everyday data analyses, such as dplyr, tidyr, tibble and many others. Url: https://www.tidyverse.org/↩\n\rThere is a more complete and comprehensive paper written by Zhao Yancheng, inspired by / used some of the code in the paper while writing the function. Yanchang Zhao, COVID-19 Data Analysis with R – Worldwide. RDataMining.com, 2020. URL: http://www.rdatamining.com/docs/Coronavirus-data-analysis-world.pdf↩\n\r\r\r","permalink":"/2020/05/covid19-ggplot2/","tags":["covid19","datascience","ggplot2","markdown","r","r markdown","r studio","tidyverse"],"title":"Simple Visualizations About Covid19 Cases Using ggplot2"}]